{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4181444",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from autogluon.tabular import TabularPredictor\n",
    "import mlflow\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b62f10ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('../data/processed/X_train.csv')\n",
    "y_train = pd.read_csv('../data/processed/y_train.csv')\n",
    "\n",
    "y_train = y_train.squeeze() # converts series to dataframe with one column\n",
    "train_data = X_train.copy()\n",
    "train_data['churn'] = y_train\n",
    "\n",
    "train_data.to_csv('../data/processed/train_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71c0df8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('../data/processed/X_test.csv')\n",
    "y_test = pd.read_csv('../data/processed/y_test.csv')\n",
    "y_test = y_test.squeeze()\n",
    "test_data = X_test.copy()\n",
    "test_data['churn'] = y_test\n",
    "test_data.to_csv('../data/processed/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b7e0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20251105_090618\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.12.10\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP PREEMPT_DYNAMIC Fri May  2 14:22:13 UTC 2025\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.54 GB / 11.47 GB (22.1%)\n",
      "Disk Space Avail:   27.05 GB / 236.42 GB (11.4%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Using hyperparameters preset: hyperparameters='default'\n",
      "Beginning AutoGluon training ... Time limit = 3600s\n",
      "AutoGluon will save models to \"/home/baggybro/skills/machine/churn-platform/notebooks/AutogluonModels/ag-20251105_090618\"\n",
      "Train Data Rows:    8000\n",
      "Train Data Columns: 10\n",
      "Label Column:       churn\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [np.int64(1), np.int64(0)]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2613.06 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.61 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 10 | ['CreditScore', 'Geography', 'Gender', 'Age', 'Tenure', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 7 | ['CreditScore', 'Geography', 'Age', 'Tenure', 'Balance', ...]\n",
      "\t\t('int', ['bool']) : 3 | ['Gender', 'HasCrCard', 'IsActiveMember']\n",
      "\t0.1s = Fit runtime\n",
      "\t10 features in original data used to generate 10 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.45 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 7200, Val Rows: 800\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT ... Training model for up to 3599.92s of the 3599.91s of remaining time.\n",
      "\tFitting with cpus=4, gpus=0, mem=0.0/2.6 GB\n",
      "\t0.8625\t = Validation score   (accuracy)\n",
      "\t0.58s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 3599.33s of the 3599.32s of remaining time.\n",
      "\tFitting with cpus=4, gpus=0, mem=0.0/2.5 GB\n",
      "\t0.87\t = Validation score   (accuracy)\n",
      "\t0.74s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ... Training model for up to 3598.56s of the 3598.56s of remaining time.\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\t0.8525\t = Validation score   (accuracy)\n",
      "\t0.79s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ... Training model for up to 3597.67s of the 3597.67s of remaining time.\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\t0.86\t = Validation score   (accuracy)\n",
      "\t0.89s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 3596.68s of the 3596.68s of remaining time.\n",
      "\tFitting with cpus=4, gpus=0\n",
      "\t0.8725\t = Validation score   (accuracy)\n",
      "\t1.13s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ... Training model for up to 3595.54s of the 3595.54s of remaining time.\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\t0.8612\t = Validation score   (accuracy)\n",
      "\t0.91s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ... Training model for up to 3594.43s of the 3594.42s of remaining time.\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\t0.8575\t = Validation score   (accuracy)\n",
      "\t0.8s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 3593.36s of the 3593.35s of remaining time.\n",
      "\tFitting with cpus=4, gpus=0, mem=0.0/2.6 GB\n",
      "\t0.87\t = Validation score   (accuracy)\n",
      "\t7.7s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 3585.63s of the 3585.62s of remaining time.\n",
      "\tFitting with cpus=4, gpus=0\n",
      "\t0.8612\t = Validation score   (accuracy)\n",
      "\t0.35s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 3585.26s of the 3585.26s of remaining time.\n",
      "\tFitting with cpus=4, gpus=0, mem=0.0/2.6 GB\n",
      "/home/baggybro/skills/machine/churn-platform/venv/lib64/python3.12/site-packages/sklearn/compose/_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t0.8675\t = Validation score   (accuracy)\n",
      "\t12.67s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 3572.57s of the 3572.57s of remaining time.\n",
      "\tFitting with cpus=4, gpus=0, mem=0.0/2.5 GB\n",
      "\t0.865\t = Validation score   (accuracy)\n",
      "\t1.4s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 3571.11s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost': 1.0}\n",
      "\t0.8725\t = Validation score   (accuracy)\n",
      "\t0.08s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 29.0s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 355788.7 rows/s (800 batch size)\n",
      "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (800 rows).\n",
      "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/baggybro/skills/machine/churn-platform/notebooks/AutogluonModels/ag-20251105_090618\")\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m predictor_path = \u001b[33m\"\u001b[39m\u001b[33mautogluon_predictor\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     18\u001b[39m predictor.save(predictor_path)             \u001b[38;5;66;03m# This creates the folder\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m os.path.isdir(predictor_path)       \u001b[38;5;66;03m# Handy check in your code\u001b[39;00m\n\u001b[32m     20\u001b[39m mlflow.log_artifacts(predictor_path)       \u001b[38;5;66;03m# This logs the folder contents in MLflow\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# log summary metric (accuracy)\u001b[39;00m\n",
      "\u001b[31mAssertionError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "label = 'churn'\n",
    "\n",
    "mlflow.set_experiment('churn-prediction-automl')\n",
    "\n",
    "with mlflow.start_run(run_name=\"AutoGluon_Classification\"):\n",
    "    # train autoML model\n",
    "    predictor = TabularPredictor(label=label).fit(train_data, time_limit=3600)\n",
    "\n",
    "    # evaluate on test set\n",
    "    perf = predictor.evaluate(test_data)\n",
    "\n",
    "    # log leaderboard as csv\n",
    "    leaderboard = predictor.leaderboard(silent=True)\n",
    "    leaderboard.to_csv(\"automl_leaderboard.csv\", index=False)\n",
    "    mlflow.log_artifact(\"automl_leaderboard.csv\")\n",
    "\n",
    "    # Save predictor to a deterministic absolute path and log directory\n",
    "    predictor_dir = os.path.abspath(\"./autogluon_predictor\")\n",
    "    os.makedirs(predictor_dir, exist_ok=True)\n",
    "    predictor.save(predictor_dir)\n",
    "    save_dir = predictor.path\n",
    "    assert isinstance(save_dir, str) and os.path.isdir(save_dir)\n",
    "    mlflow.log_artifacts(save_dir)\n",
    "\n",
    "    # log summary metric (accuracy)\n",
    "    accuracy = perf.get('accuracy', None)\n",
    "    if accuracy is not None:\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "    print(\"AutoML training completed and logged in MLflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93034001",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
